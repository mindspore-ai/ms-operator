# wide&deep for only one worker training, just like in one machine which has 1 gpu.
# network : https://gitee.com/mindspore/models/tree/master/official/recommend/wide_and_deep
apiVersion: mindspore.gitee.com/v1
kind: MSJob
metadata:
  name: ms-widedeep-single-worker
spec:
  msReplicaSpecs:
    Worker:
      replicas: 1
      restartPolicy: Never
      template:
        spec:
          volumes:
            - name: script-data
              hostPath:
                path: /home/fzh/wide_and_deep/
          containers:
            - name: mindspore
              image: swr.cn-south-1.myhuaweicloud.com/mindspore/mindspore-gpu-cuda10.1:1.6.0
              imagePullPolicy: IfNotPresent
              command:
                - /bin/bash
                - -c
                - pip install decorator -i http://cmc-cd-mirror.rnd.huawei.com/pypi/simple/ --trusted-host=cmc-cd-mirror.rnd.huawei.com; python -s /home/fzh/wide_and_deep/train_and_eval.py --device_target="GPU" --data_path=/home/fzh/wide_and_deep/criteo_mindrecord --batch_size=16000 --epochs=1
              volumeMounts:
                - mountPath: /home/fzh/wide_and_deep/
                  name: script-data